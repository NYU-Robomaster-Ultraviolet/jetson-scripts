{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import serial\n",
    "import numpy as np\n",
    "from turtle import color\n",
    "import matplotlib\n",
    "from Realsense.realsense_depth import *\n",
    "from Realsense.realsense import *\n",
    "from Algorithm.main import *\n",
    "import cv2\n",
    "import time\n",
    "import argparse\n",
    "import struct\n",
    "from UART.uart import uart_server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('TKAgg')\n",
    "# Disable tensorflow output\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize CV Cameras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize CV Camera\n",
    "class DepthCamera:\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        # Configure depth and color streams\n",
    "        self.pipeline = rs.pipeline()\n",
    "        config = rs.config()\n",
    "\n",
    "        # Get device product line for setting a supported resolution\n",
    "        pipeline_wrapper = rs.pipeline_wrapper(self.pipeline)\n",
    "        pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "\n",
    "        #Init streams\n",
    "        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "        #Disable laser\n",
    "        device = pipeline_profile.get_device()\n",
    "        depth_sensor=device.query_sensors()[0]\n",
    "        depth_sensor.set_option(rs.option.laser_power, 0)\n",
    "        \n",
    "        # Start streaming\n",
    "        self.pipeline.start(config)\n",
    "\n",
    "    # Get Depth and Color Frame\n",
    "    def get_frame(self):\n",
    "        try:\n",
    "            frames = self.pipeline.wait_for_frames()\n",
    "        except:\n",
    "            return False, None, None\n",
    "            \n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        if not depth_frame or not color_frame:\n",
    "            return False, None, None\n",
    "\n",
    "        return True, depth_image, color_image\n",
    "\n",
    "    def release(self):\n",
    "        self.pipeline.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV Loop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a CV capture class\n",
    "# Make a struct to keep track of bounding boxes per robot (4 total plates per robot)\n",
    "\n",
    "\n",
    "\n",
    "class Capture:\n",
    "    # Constructor with depth camera\n",
    "    def __init__(self, dc=None, camera_index=0, is_realsense=True):\n",
    "        # Check if realsense class depth camera object is passed or an integer for the index of a regular camera\n",
    "        self.is_realsense = True\n",
    "        if is_realsense:\n",
    "            if dc == None:\n",
    "                self.dc = DepthCamera()\n",
    "            else:\n",
    "                self.dc = dc\n",
    "        else:\n",
    "            self.cap = cv2.VideoCapture(camera_index)\n",
    "            self.is_realsense=False\n",
    "\n",
    "        self.model = self.load_model()\n",
    "\n",
    "        self.robot_list = []\n",
    "\n",
    "\n",
    "\n",
    "    # Deconstructor\n",
    "    def __del__(self):\n",
    "        if self.is_realsense:\n",
    "            self.dc.release()\n",
    "\n",
    "\n",
    "    def load_model(self):\n",
    "        # or yolov5m, yolov5l, yolov5x, custom\n",
    "        model = torch.hub.load('ultralytics/yolov5', 'custom',\n",
    "                           path='./Algorithm/pt_files/best.pt')\n",
    "        return model\n",
    "\n",
    "    # Get Depth and Color Frame\n",
    "    def capture_pipeline(self, debug=False, display=False):\n",
    "        while True:\n",
    "            # Get frame from camera\n",
    "            try:\n",
    "                ret, depth_image, color_image = self.dc.get_frame()\n",
    "            except:\n",
    "                print(\"Error getting frame\")\n",
    "\n",
    "            if ret:\n",
    "                key = cv2.waitKey(1)\n",
    "                if key == 27:\n",
    "                    break\n",
    "\n",
    "                # Frame is valid\n",
    "                self.process_frame(color_image=color_image, debug=debug, display=display)\n",
    "\n",
    "    # Process a color frame \n",
    "    def process_frame(self, color_image, debug=False, display=False):\n",
    "        conf_thres = 0.25  # Confidence threshold\n",
    "        # Get bounding boxes\n",
    "        results = self.model(color_image)\n",
    "        \n",
    "        # Post process bounding boxes\n",
    "        #rows = results.pandas().xyxy[0].to_numpy()\n",
    "\n",
    "        detections_rows = results.pandas().xyxy\n",
    "\n",
    "        for i in range(len(detections_rows)):\n",
    "            rows = detections_rows[i].to_numpy()\n",
    "\n",
    "        # Go through all detections\n",
    "\n",
    "        for i in range(len(rows)):\n",
    "            if len(rows) > 0:\n",
    "                # Get the bounding box of the first object (most confident)\n",
    "                x_min, y_min, x_max, y_max, conf, cls, label = rows[i]\n",
    "                  # Coordinate system is as follows:\n",
    "                  # 0,0 is the top left corner of the image\n",
    "                  # x is the horizontal axis\n",
    "                  # y is the vertical axis\n",
    "                  # x_max, y_max is the bottom right corner of the screen\n",
    "                  \n",
    "                  # (0,0) --------> (x_max, 0)\n",
    "                  # |               |\n",
    "                  # |               |\n",
    "                  # |               |\n",
    "                  # |               |\n",
    "                  # |               |\n",
    "                  # (0, y_max) ----> (x_max, y_max)\n",
    "                if debug:\n",
    "                    print(\"({},{}) \\n\\n\\n                     ({},{})\".format(x_min, y_min, x_max, y_max))\n",
    "                    os.system('cls')\n",
    "                    os.system('clear')\n",
    "\n",
    "                if display:\n",
    "                    bbox = [x_min, y_min, x_max, y_max]\n",
    "                    color_image = self.write_bbx_frame(color_image, bbox, label, conf)\n",
    "        # Display the image\n",
    "        cv2.imshow('RealSense', color_image)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "\n",
    "    def write_bbx_frame(self, color_image, bbxs, label, conf):\n",
    "        # Display the bounding box\n",
    "        x_min, y_min, x_max, y_max = bbxs\n",
    "        cv2.rectangle(color_image, (int(x_min), int(y_min)), (int(\n",
    "            x_max), int(y_max)), (0, 255, 0), 2)  # Draw with green color\n",
    "\n",
    "        # Display the label with the confidence\n",
    "        label_conf = label + \" \" + str(conf)\n",
    "        cv2.putText(color_image, label_conf, (int(x_min), int(\n",
    "            y_min)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        return color_image\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_stream = Capture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_stream.capture_pipeline(debug=True, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a CV capture class, track plates using median flow tracker, and use the tracker to track the robot\n",
    "\n",
    "\n",
    "class Capture_Track:\n",
    "    # Constructor with depth camera\n",
    "    def __init__(self, dc=None, camera_index=0, is_realsense=True):\n",
    "        # Check if realsense class depth camera object is passed or an integer for the index of a regular camera\n",
    "        self.is_realsense = True\n",
    "        if is_realsense:\n",
    "            if dc == None:\n",
    "                self.dc = DepthCamera()\n",
    "            else:\n",
    "                self.dc = dc\n",
    "        else:\n",
    "            self.cap = cv2.VideoCapture(camera_index)\n",
    "            self.is_realsense = False\n",
    "\n",
    "        self.model = self.load_model()\n",
    "\n",
    "        self.robot_list = []\n",
    "        #Tracker median flow\n",
    "        self.tracker = cv2.legacy.TrackerMedianFlow_create()\n",
    "        self.seen_first = False\n",
    "\n",
    "    # Deconstructor\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.is_realsense:\n",
    "            self.dc.release()\n",
    "\n",
    "    def load_model(self):\n",
    "        # or yolov5m, yolov5l, yolov5x, custom\n",
    "        model = torch.hub.load('ultralytics/yolov5', 'custom',\n",
    "                               path='./Algorithm/pt_files/best.pt')\n",
    "        return model\n",
    "\n",
    "    # Get Depth and Color Frame\n",
    "    def capture_pipeline(self, debug=False, display=False):\n",
    "        while True:\n",
    "            # Get frame from camera\n",
    "            try:\n",
    "                ret, depth_image, color_image = self.dc.get_frame()\n",
    "            except:\n",
    "                print(\"Error getting frame\")\n",
    "\n",
    "            if ret:\n",
    "                key = cv2.waitKey(1)\n",
    "                if key == 27:\n",
    "                    break\n",
    "\n",
    "                # Frame is valid\n",
    "                self.process_frame(color_image=color_image,\n",
    "                                   debug=debug, display=display)\n",
    "\n",
    "    # Process a color frame\n",
    "    def process_frame(self, color_image, debug=False, display=False):\n",
    "        conf_thres = 0.25  # Confidence threshold\n",
    "        # Get bounding boxes\n",
    "        results = self.model(color_image)\n",
    "\n",
    "        # Post process bounding boxes\n",
    "        #rows = results.pandas().xyxy[0].to_numpy()\n",
    "\n",
    "        detections_rows = results.pandas().xyxy\n",
    "\n",
    "        for i in range(len(detections_rows)):\n",
    "            rows = detections_rows[i].to_numpy()\n",
    "\n",
    "        # Go through all detections\n",
    "\n",
    "        for i in range(len(rows)):\n",
    "            if len(rows) > 0:\n",
    "                # Get the bounding box of the first object (most confident)\n",
    "                x_min, y_min, x_max, y_max, conf, cls, label = rows[i]\n",
    "                # We will only track 1st plate\n",
    "                if i == 0:\n",
    "                  # Initialize tracker with first frame and bounding box\n",
    "                  if display:\n",
    "                        if self.seen_first == False:\n",
    "                              self.seen_first = True\n",
    "                              ok = self.tracker.init(color_image, (x_min, y_min, x_max, y_max))\n",
    "                        else:\n",
    "                              # Update tracker\n",
    "                              ok, bbox = self.tracker.update(color_image)\n",
    "                              # Draw bounding box\n",
    "                              if ok:\n",
    "                                    # Tracking success\n",
    "                                    p1 = (int(bbox[0]), int(bbox[1]))\n",
    "                                    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "                                    cv2.rectangle(color_image, p1, p2, (255,0,0), 2, 1)\n",
    "                              else :\n",
    "                                    # Tracking failure\n",
    "                                    cv2.putText(color_image, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "\n",
    "\n",
    "                # Coordinate system is as follows:\n",
    "                # 0,0 is the top left corner of the image\n",
    "                # x is the horizontal axis\n",
    "                # y is the vertical axis\n",
    "                # x_max, y_max is the bottom right corner of the screen\n",
    "\n",
    "                # (0,0) --------> (x_max, 0)\n",
    "                # |               |\n",
    "                # |               |\n",
    "                # |               |\n",
    "                # |               |\n",
    "                # |               |\n",
    "                # (0, y_max) ----> (x_max, y_max)\n",
    "                if debug:\n",
    "                    print(\"({},{}) \\n\\n\\n                     ({},{})\".format(\n",
    "                        x_min, y_min, x_max, y_max))\n",
    "                    os.system('cls')\n",
    "                    os.system('clear')\n",
    "\n",
    "                if display:\n",
    "                    bbox = [x_min, y_min, x_max, y_max]\n",
    "                    color_image = self.write_bbx_frame(\n",
    "                        color_image, bbox, label, conf)\n",
    "        # Display the image\n",
    "        cv2.imshow('RealSense', color_image)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    def write_bbx_frame(self, color_image, bbxs, label, conf):\n",
    "        # Display the bounding box\n",
    "        x_min, y_min, x_max, y_max = bbxs\n",
    "        cv2.rectangle(color_image, (int(x_min), int(y_min)), (int(\n",
    "            x_max), int(y_max)), (0, 255, 0), 2)  # Draw with green color\n",
    "\n",
    "        # Display the label with the confidence\n",
    "        label_conf = label + \" \" + str(conf)\n",
    "        cv2.putText(color_image, label_conf, (int(x_min), int(\n",
    "            y_min)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        return color_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_stream = Capture_Track()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_stream.capture_pipeline(debug=True, display=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('CVRM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8831e653196f0dd636f7860080e11b20dcbfd7a06f3bf540d5099e7e7b1fd0ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
